import OpenAI from "openai";
import type { Material, Subject, Topic, Goal, KnowledgeBase } from "@shared/schema";
import { storage } from "../storage";
import { embeddingsService } from "./embeddings";
import { webSearch, type WebSearchResult } from "./web-search";
import { ragService } from "./rag";
import fs from "fs";
import path from "path";
import mammoth from "mammoth";

// Initialize OpenRouter client for DeepSeek R1
const openai = new OpenAI({
  apiKey: process.env.OPENROUTER_API_KEY,
  baseURL: "https://openrouter.ai/api/v1",
});

export interface QuestionGenerationRequest {
  subject: Subject;
  topic?: Topic;
  materials: Material[];
  studyProfile: string;
  difficulty: "easy" | "medium" | "hard";
  questionCount: number;
}

export interface GeneratedQuestion {
  question: string;
  options: string[];
  correctAnswer: string;
  explanation: string;
  difficulty: string;
}

export interface FlashcardGenerationRequest {
  content: string;
  studyProfile: string;
  subject?: string;
  count: number;
}

export interface GeneratedFlashcard {
  front: string;
  back: string;
}

export class AIService {
  async generateQuestions(request: QuestionGenerationRequest): Promise<GeneratedQuestion[]> {
    const { subject, topic, materials, studyProfile, difficulty, questionCount } = request;

    // Build context from materials
    const materialContext = materials
      .map(m => `Material: ${m.title}\nType: ${m.type}\nContent: ${m.content || m.description || 'No content available'}`)
      .join('\n\n');

    const topicInfo = topic ? `Topic: ${topic.name} - ${topic.description}` : '';

    // Customize prompt based on study profile
    const profileStrategies = {
      disciplined: "Generate challenging questions that require deep understanding and application of concepts. Focus on analytical and problem-solving questions.",
      undisciplined: "Generate engaging, practical questions with real-world applications. Use varied question formats to maintain interest and motivation.",
      average: "Generate a balanced mix of theoretical and practical questions with clear explanations to reinforce learning."
    };

    const strategy = profileStrategies[studyProfile as keyof typeof profileStrategies] || profileStrategies.average;

    const prompt = `You are an expert educator creating personalized study questions.

Subject: ${subject.name} - ${subject.description}
${topicInfo}
Study Profile: ${studyProfile}
Strategy: ${strategy}
Difficulty Level: ${difficulty}

Materials to base questions on:
${materialContext}

Generate ${questionCount} multiple-choice questions based on the provided materials. Each question should:
1. Be directly related to the content in the materials
2. Match the ${difficulty} difficulty level
3. Be appropriate for a ${studyProfile} student
4. Have 4 options (A, B, C, D)
5. Include a clear explanation of the correct answer

Respond with a JSON object containing an array of questions in this exact format:
{
  "questions": [
    {
      "question": "Question text here",
      "options": ["A) Option 1", "B) Option 2", "C) Option 3", "D) Option 4"],
      "correctAnswer": "A",
      "explanation": "Detailed explanation of why this answer is correct and why others are wrong",
      "difficulty": "${difficulty}"
    }
  ]
}`;

    try {
      const response = await openai.chat.completions.create({
        model: "deepseek/deepseek-r1",
        messages: [
          {
            role: "user",
            content: prompt
          }
        ],
        temperature: 0.7,
        max_tokens: 3000,
      });

      const text = response.choices[0]?.message?.content;
      if (!text) {
        throw new Error("No response from AI");
      }
      
      // Clean JSON response
      const jsonMatch = text.match(/\{[\s\S]*\}/);
      if (!jsonMatch) {
        throw new Error("No valid JSON found in response");
      }
      
      const parsed = JSON.parse(jsonMatch[0]);
      return parsed.questions || [];
    } catch (error) {
      console.error("Error generating questions:", error);
      throw new Error("Failed to generate questions: " + (error as Error).message);
    }
  }

  async generateStudyRecommendation(
    studyProfile: string,
    subjects: Subject[],
    recentPerformance: any[]
  ): Promise<string> {
    const prompt = `Based on the following student profile and performance data, provide a personalized study recommendation.

Study Profile: ${studyProfile}
Subjects: ${subjects.map(s => `${s.name} (${s.category})`).join(', ')}
Recent Performance: ${recentPerformance.length > 0 ? 
  recentPerformance.map(p => `${p.subject}: ${p.score}%`).join(', ') : 
  'No recent performance data'
}

Provide a concise, actionable study recommendation (2-3 sentences) tailored to this student's profile and current progress.`;

    try {
      const response = await openai.chat.completions.create({
        model: "deepseek/deepseek-r1",
        messages: [
          {
            role: "user",
            content: prompt
          }
        ],
        temperature: 0.7,
        max_tokens: 200,
      });

      const text = response.choices[0]?.message?.content;
      return text || "Continue with your current study plan and focus on consistent practice.";
    } catch (error) {
      console.error("Error generating recommendation:", error);
      return "Keep up the good work! Focus on areas where you need more practice and maintain a consistent study schedule.";
    }
  }

  // üß† SISTEMA INTELIGENTE DE SELE√á√ÉO DE MODELO
  private selectOptimalModel(question: string, knowledgeContext: string, webContext: string): {
    model: string;
    name: string;
    temperature: number;
    maxTokens: number;
    topP: number;
    reasoning: string;
  } {
    const questionLower = question.toLowerCase();
    const hasComplexContext = knowledgeContext.length > 500 || webContext.length > 500;
    
    // üìä DETECTAR PERGUNTAS SOBRE TABELAS/AN√ÅLISES (Claude 3.5 Sonnet - Alta qualidade)
    const tableKeywords = ['tabela', 'table', 'comparar', 'compare', 'an√°lise', 'analysis', 'classificar', 'classify', 'organizar', 'organize', 'estruturar', 'listar detalhadamente', 'diferen√ßas entre', 'semelhan√ßas', 'quadro', 'matriz', 'planilha', 'dados organizados'];
    const isTableAnalysis = tableKeywords.some(keyword => questionLower.includes(keyword));
    
    // üíª DETECTAR PERGUNTAS T√âCNICAS/C√ìDIGO (DeepSeek V3 - Especializado)
    const techKeywords = ['c√≥digo', 'code', 'programar', 'programming', 'algoritmo', 'algorithm', 'fun√ß√£o', 'function', 'javascript', 'python', 'sql', 'html', 'css', 'api', 'debug', 'erro t√©cnico', 'implementar', 'desenvolvimento'];
    const isTechnical = techKeywords.some(keyword => questionLower.includes(keyword));
    
    // üìù DETECTAR PERGUNTAS COMPLEXAS QUE PRECISAM DE ALTA QUALIDADE
    const complexKeywords = ['explique detalhadamente', 'an√°lise profunda', 'compare detalhadamente', 'disserta√ß√£o', 'ensaio', 'reda√ß√£o', 'argumenta√ß√£o', 'fundamenta√ß√£o te√≥rica'];
    const isComplex = complexKeywords.some(keyword => questionLower.includes(keyword)) || hasComplexContext;
    
    // üìä L√ìGICA DE SELE√á√ÉO INTELIGENTE
    if (isTableAnalysis || question.length > 200) {
      return {
        model: "anthropic/claude-3.5-sonnet",
        name: "Claude 3.5 Sonnet (Tabelas/An√°lises)",
        temperature: 0.4,
        maxTokens: 1500,
        topP: 0.85,
        reasoning: "Pergunta sobre tabelas/an√°lises ou muito longa - usando Claude para m√°xima qualidade"
      };
    }
    
    if (isTechnical) {
      return {
        model: "deepseek/deepseek-v3",
        name: "DeepSeek V3 (T√©cnico)",
        temperature: 0.3,
        maxTokens: 1200,
        topP: 0.8,
        reasoning: "Pergunta t√©cnica - usando DeepSeek V3 especializado"
      };
    }
    
    if (isComplex || hasComplexContext) {
      return {
        model: "anthropic/claude-3.5-sonnet",
        name: "Claude 3.5 Sonnet (Complexo)",
        temperature: 0.5,
        maxTokens: 1200,
        topP: 0.9,
        reasoning: "Pergunta complexa ou muito contexto - usando Claude para melhor qualidade"
      };
    }
    
    // üí∞ PADR√ÉO: Perguntas gerais (DeepSeek R1 - Econ√¥mico)
    return {
      model: "deepseek/deepseek-r1",
      name: "DeepSeek R1 (Geral)",
      temperature: 0.7,
      maxTokens: 1000,
      topP: 0.9,
      reasoning: "Pergunta geral - usando modelo econ√¥mico"
    };
  }

  // ‚ö° OTIMIZA√á√ÉO AUTOM√ÅTICA DE CONTEXTO para evitar limites de tokens
  private optimizePromptSize(prompt: string, selectedModel: any): string {
    // Aproxima√ß√£o: 1 token ‚âà 4 caracteres em portugu√™s
    const estimatedTokens = Math.ceil(prompt.length / 4);
    
    // Limites seguros por modelo (deixando margem para resposta)
    const tokenLimits = {
      'anthropic/claude-3.5-sonnet': 8000, // Limite seguro para contas free
      'deepseek/deepseek-v3': 6000,
      'deepseek/deepseek-r1': 15000, // Modelo mais generoso
    };
    
    const maxTokens = tokenLimits[selectedModel.model as keyof typeof tokenLimits] || 6000;
    
    if (estimatedTokens <= maxTokens) {
      console.log(`üìè Prompt OK: ${estimatedTokens} tokens (limite: ${maxTokens})`);
      return prompt;
    }

    console.log(`‚ö†Ô∏è Prompt muito grande: ${estimatedTokens} tokens, truncando para ${maxTokens}`);
    
    // Estrat√©gia de truncamento inteligente:
    // 1. Manter pergunta original (mais importante)
    // 2. Reduzir contexto de conhecimento
    // 3. Reduzir contexto web
    
    const lines = prompt.split('\n');
    let truncatedLines: string[] = [];
    let currentTokens = 0;
    let inKnowledgeSection = false;
    let inWebSection = false;
    let knowledgeLines = 0;
    let webLines = 0;
    
    // Primeira passagem: identificar se√ß√µes e manter estrutura essencial
    for (const line of lines) {
      const lineTokens = Math.ceil(line.length / 4);
      
      // Detectar se√ß√µes
      if (line.includes('üìö BASE DE CONHECIMENTO')) {
        inKnowledgeSection = true;
        inWebSection = false;
      } else if (line.includes('üåê INFORMA√á√ïES DA INTERNET')) {
        inKnowledgeSection = false;
        inWebSection = true;
      }
      
      // Sempre manter: pergunta, instru√ß√µes, formato
      const isEssential = !inKnowledgeSection && !inWebSection;
      
      if (isEssential) {
        if (currentTokens + lineTokens <= maxTokens) {
          truncatedLines.push(line);
          currentTokens += lineTokens;
        }
      } else if (inKnowledgeSection && knowledgeLines < 20) {
        // Limitar conhecimento a 20 linhas mais importantes
        if (currentTokens + lineTokens <= maxTokens) {
          truncatedLines.push(line);
          currentTokens += lineTokens;
          knowledgeLines++;
        }
      } else if (inWebSection && webLines < 10) {
        // Limitar web a 10 linhas mais importantes
        if (currentTokens + lineTokens <= maxTokens) {
          truncatedLines.push(line);
          currentTokens += lineTokens;
          webLines++;
        }
      }
    }
    
    const truncatedPrompt = truncatedLines.join('\n');
    const finalTokens = Math.ceil(truncatedPrompt.length / 4);
    
    console.log(`‚úÖ Prompt otimizado: ${finalTokens} tokens (reduzido de ${estimatedTokens})`);
    
    // Se ainda assim for muito grande, cortar mais drasticamente
    if (finalTokens > maxTokens) {
      const targetChars = maxTokens * 4;
      const drasticPrompt = truncatedPrompt.substring(0, targetChars);
      console.log(`üî• Corte dr√°stico aplicado para ${Math.ceil(drasticPrompt.length / 4)} tokens`);
      return drasticPrompt + '\n\n‚ö†Ô∏è Contexto reduzido devido a limites de tokens. Responda com base no conte√∫do dispon√≠vel.';
    }
    
    return truncatedPrompt;
  }

  /**
   * NOVO: Chat com IA usando RAG - sempre consulta base primeiro
   */
  async chatWithAI(question: string, studyProfile: string, subjects: Subject[], selectedGoal?: any, userId?: string, selectedKnowledgeCategory?: string): Promise<string> {
    // Se temos userId, usar o novo sistema RAG
    if (userId) {
      try {
        console.log(`ü§ñ AI Assistant RAG ativado para: "${question.substring(0, 100)}..."`);
        
        const ragResponse = await ragService.generateContextualResponse({
          userId,
          query: question,
          category: selectedKnowledgeCategory,
          model: 'gpt-4o-mini'
        });

        return ragResponse.response;
      } catch (error) {
        console.error('‚ùå Erro no RAG Assistant:', error);
        // Fallback para o m√©todo anterior
      }
    }

    // M√©todo anterior como fallback
    // FASE 1: Busca INTELIGENTE na base de conhecimento
    let knowledgeContext = '';
    let hasPersonalKnowledge = false;
    
    if (userId) {
      try {
        // Busca com embeddings (mais precisa)
        const queryEmbedding = await embeddingsService.generateEmbedding(question);
        const embeddingResults = await storage.searchKnowledgeBaseWithEmbeddings(userId, queryEmbedding, 5, selectedKnowledgeCategory);
        
        // Busca tradicional por keywords (mais abrangente)
        const keywordResults = await storage.searchKnowledgeBase(userId, question, selectedKnowledgeCategory);
        
        // Combinar resultados para ter informa√ß√£o completa
        if (embeddingResults.length > 0 || keywordResults) {
          hasPersonalKnowledge = true;
          knowledgeContext = '\nüìö BASE DE CONHECIMENTO PESSOAL:\n';
          
          if (embeddingResults.length > 0) {
            embeddingResults.forEach((result, index) => {
              knowledgeContext += `[${result.title}]\n${result.content}\n\n`;
            });
          }
          
          if (keywordResults && !embeddingResults.some(r => keywordResults.includes(r.content))) {
            knowledgeContext += `${keywordResults}\n\n`;
          }
        }
      } catch (error) {
        console.error("Erro ao buscar na base de conhecimento:", error);
      }
    }

    // FASE 2: Busca na internet SOMENTE se n√£o tiver informa√ß√£o suficiente
    let webContext = '';
    
    // Se n√£o tem conhecimento pessoal OU conhecimento √© muito limitado, buscar na internet
    if (!hasPersonalKnowledge || knowledgeContext.length < 200) {
      try {
        const webResults = await webSearch.search(question, 3);
        if (webResults.length > 0) {
          webContext = '\nüåê INFORMA√á√ïES DA INTERNET:\n';
          webResults.forEach((result, index) => {
            webContext += `[${result.title}]\n${result.content}\n\n`;
          });
        }
      } catch (error) {
        console.error("Erro na busca web:", error);
      }
    }

    // Customize prompt based on study profile
    const profileContext = {
      disciplined: "Voc√™ est√° falando com um estudante disciplinado que prefere desafios e an√°lises profundas. Seja espec√≠fico e ofere√ßa t√©cnicas avan√ßadas.",
      undisciplined: "Voc√™ est√° falando com um estudante que precisa de motiva√ß√£o e t√©cnicas pr√°ticas. Seja encorajador e sugira m√©todos variados e interessantes.",
      average: "Voc√™ est√° falando com um estudante mediano. Forne√ßa conselhos equilibrados entre teoria e pr√°tica, simples de seguir."
    };

    const context = profileContext[studyProfile as keyof typeof profileContext] || profileContext.average;
    const subjectsList = subjects.length > 0 ? 
      `O estudante est√° estudando: ${subjects.map(s => `${s.name} (${s.category})`).join(', ')}.` : 
      'O estudante ainda n√£o cadastrou mat√©rias espec√≠ficas.';

    // Adicionar contexto da meta se selecionada
    let goalContext = '';
    if (selectedGoal) {
      goalContext = `\n- OBJETIVO PRINCIPAL: ${selectedGoal.title}`;
      if (selectedGoal.description) {
        goalContext += ` - ${selectedGoal.description}`;
      }
      if (selectedGoal.targetDate) {
        const targetDate = new Date(selectedGoal.targetDate);
        goalContext += ` (Prazo: ${targetDate.toLocaleDateString('pt-BR')})`;
      }
      goalContext += '\n- IMPORTANTE: Todas as suas respostas devem ser direcionadas para ajudar com este objetivo espec√≠fico.';
    }

    // FASE 3: Criar prompt robusto que FORCE o uso do conte√∫do
    const robustPrompt = this.createRobustPrompt({
      question,
      studyProfile,
      context,
      subjectsList,
      goalContext,
      knowledgeContext,
      webContext,
      hasPersonalKnowledge,
      selectedGoal
    });

    let prompt = robustPrompt;

    try {
      // üß† SELE√á√ÉO INTELIGENTE DE MODELO baseado no tipo de pergunta
      let selectedModel = this.selectOptimalModel(question, knowledgeContext, webContext);
      console.log(`üéØ Modelo selecionado: ${selectedModel.name} para "${question.substring(0, 50)}..."`);

      // ‚ö° OTIMIZA√á√ÉO AUTOM√ÅTICA DE CONTEXTO para evitar limite de tokens
      prompt = this.optimizePromptSize(prompt, selectedModel);

      // üîÑ FALLBACK AUTOM√ÅTICO: se prompt ainda muito grande, usar modelo econ√¥mico
      const estimatedTokens = Math.ceil(prompt.length / 4);
      if (estimatedTokens > 8000 && selectedModel.model !== 'deepseek/deepseek-r1') {
        console.log(`üîÑ Fallback: Prompt muito grande (${estimatedTokens} tokens), mudando para DeepSeek R1`);
        selectedModel = {
          model: "deepseek/deepseek-r1",
          name: "DeepSeek R1 (Fallback)",
          temperature: 0.7,
          maxTokens: 1200,
          topP: 0.9,
          reasoning: "Fallback devido a limite de tokens"
        };
      }

      // SISTEMA DE REVIS√ÉO AUTOM√ÅTICA COM AT√â 3 ITERA√á√ïES
      const maxAttempts = 3;
      let attempt = 0;
      let responseText = '';

      while (attempt < maxAttempts) {
        attempt++;
        
        const response = await openai.chat.completions.create({
          model: selectedModel.model,
          messages: [
            {
              role: "user",
              content: prompt
            }
          ],
          temperature: selectedModel.temperature,
          max_tokens: selectedModel.maxTokens,
          top_p: selectedModel.topP,
        });

        responseText = response.choices[0]?.message?.content || '';
        
        if (!responseText || responseText.trim().length === 0) {
          responseText = "Desculpe, n√£o consegui processar sua pergunta no momento. Tente novamente em alguns segundos.";
          break;
        }
        
        // Clean the response
        responseText = responseText.trim();

        // FASE 4: REVIS√ÉO AUTOM√ÅTICA DA RESPOSTA
        const reviewResult = await this.reviewResponse(question, responseText);
        
        if (reviewResult.isComplete && reviewResult.isCoherent && reviewResult.isDidactic && reviewResult.hasGoodStructure && reviewResult.isDeepEnough) {
          // Resposta aprovada na revis√£o
          console.log(`‚úÖ Resposta aprovada na tentativa ${attempt} - Qualidade verificada`);
          break;
        }
        
        if (attempt < maxAttempts) {
          // Resposta precisa ser melhorada - ajustar prompt para pr√≥xima tentativa
          console.log(`üîÑ Itera√ß√£o ${attempt}/${maxAttempts} - Problemas encontrados: ${reviewResult.issues.join(', ')}`);
          
          // Criar prompt melhorado baseado no feedback espec√≠fico da revis√£o
          const improvedPrompt = `${prompt}\n\nüö® FEEDBACK DA REVIS√ÉO (Tentativa ${attempt}):
PROBLEMAS IDENTIFICADOS: ${reviewResult.issues.join(', ')}
SUGEST√ïES: ${reviewResult.suggestions || 'Melhore a qualidade geral da resposta'}

üìã REQUISITOS OBRIGAT√ìRIOS para a pr√≥xima resposta:
‚úÖ COMPLETUDE: Responda TODOS os aspectos da pergunta sem deixar lacunas
‚úÖ DID√ÅTICA: Use linguagem clara, exemplos pr√°ticos e explica√ß√µes passo-a-passo
‚úÖ ESTRUTURA: Organize com cabe√ßalhos (##), listas, tabelas e formata√ß√£o Markdown
‚úÖ PROFUNDIDADE: Forne√ßa explica√ß√µes detalhadas, n√£o apenas respostas superficiais
‚úÖ COER√äNCIA: Mantenha fluxo l√≥gico e conex√£o entre as ideias
‚úÖ RELEV√ÇNCIA: Foque apenas no que foi perguntado

üéØ IMPORTANTE: Esta √© a tentativa ${attempt} de ${maxAttempts}. A resposta deve ser significativamente melhor que a anterior.`;
          
          // Usar o prompt melhorado na pr√≥xima tentativa com par√¢metros ajustados
          const improvedResponse = await openai.chat.completions.create({
            model: selectedModel.model,
            messages: [
              {
                role: "user",
                content: improvedPrompt
              }
            ],
            temperature: Math.max(selectedModel.temperature - 0.1, 0.4), // Reduzir criatividade para foco
            max_tokens: selectedModel.maxTokens + 200, // Mais espa√ßo para melhorias
            top_p: Math.max(selectedModel.topP - 0.05, 0.7),
          });
          
          responseText = improvedResponse.choices[0]?.message?.content || responseText;
        } else {
          console.log(`‚ö†Ô∏è M√°ximo de ${maxAttempts} tentativas atingido. Enviando melhor resposta dispon√≠vel.`);
        }
      }
      
      return responseText;
    } catch (error) {
      console.error("Error in AI chat:", error);
      
      // Return a safe fallback message instead of throwing
      if (error instanceof Error && error.message.includes('quota')) {
        return "Desculpe, o limite de uso da IA foi atingido temporariamente. Tente novamente em alguns minutos.";
      }
      
      return "Houve um problema tempor√°rio com o assistente de IA. Tente fazer sua pergunta novamente.";
    }
  }

  private async reviewResponse(originalQuestion: string, response: string): Promise<{
    isComplete: boolean;
    isCoherent: boolean;
    isDidactic: boolean;
    hasGoodStructure: boolean;
    isDeepEnough: boolean;
    issues: string[];
    suggestions?: string;
  }> {
    const reviewPrompt = `Voc√™ √© um revisor especializado em qualidade de respostas educacionais. Analise se a resposta est√° completa e coerente.

PERGUNTA ORIGINAL: ${originalQuestion}

RESPOSTA PARA REVISAR:
${response}

CRIT√âRIOS DE AVALIA√á√ÉO:
1. COMPLETUDE: A resposta responde completamente √† pergunta? N√£o deixa pontos importantes sem resposta?
2. COER√äNCIA: A resposta √© logicamente organizada? As informa√ß√µes fluem de forma natural?
3. ESTRUTURA: A resposta est√° bem formatada com t√≠tulos, listas, exemplos e se√ß√µes claras?
4. DID√ÅTICA: A explica√ß√£o √© clara, did√°tica e f√°cil de entender? Usa exemplos quando necess√°rio?
5. RELEV√ÇNCIA: Todo conte√∫do da resposta √© diretamente relacionado √† pergunta?
6. FINALIZA√á√ÉO: A resposta parece completa ou foi cortada abruptamente?
7. PROFUNDIDADE: A resposta tem profundidade adequada sem ser superficial?

Uma resposta deve ser APROVADA apenas se atender a TODOS esses crit√©rios.

Responda com JSON no seguinte formato:
{
  "isComplete": true/false,
  "isCoherent": true/false,
  "isDidactic": true/false,
  "hasGoodStructure": true/false,
  "isDeepEnough": true/false,
  "issues": ["lista espec√≠fica de problemas encontrados"],
  "suggestions": "sugest√µes detalhadas e espec√≠ficas para melhorar"
}

Seja RIGOROSO na avalia√ß√£o. Uma resposta s√≥ deve ser aprovada se for realmente completa, did√°tica e bem estruturada.`;

    try {
      const response = await openai.chat.completions.create({
        model: "deepseek/deepseek-r1",
        messages: [
          {
            role: "user",
            content: reviewPrompt
          }
        ],
        temperature: 0.3,
        max_tokens: 400,
      });

      const reviewText = response.choices[0]?.message?.content || '';
      
      // Extrair JSON da resposta
      const jsonMatch = reviewText.match(/\{[\s\S]*\}/);
      if (!jsonMatch) {
        // Se n√£o conseguir analisar, considerar aprovado por seguran√ßa
        return {
          isComplete: true,
          isCoherent: true,
          isDidactic: true,
          hasGoodStructure: true,
          isDeepEnough: true,
          issues: [],
          suggestions: undefined
        };
      }
      
      const reviewResult = JSON.parse(jsonMatch[0]);
      
      // Validar estrutura do resultado
      return {
        isComplete: reviewResult.isComplete || false,
        isCoherent: reviewResult.isCoherent || false,
        isDidactic: reviewResult.isDidactic || false,
        hasGoodStructure: reviewResult.hasGoodStructure || false,
        isDeepEnough: reviewResult.isDeepEnough || false,
        issues: Array.isArray(reviewResult.issues) ? reviewResult.issues : [],
        suggestions: reviewResult.suggestions || undefined
      };
      
    } catch (error) {
      console.error("Erro na revis√£o da resposta:", error);
      // Em caso de erro, considerar aprovado por seguran√ßa
      return {
        isComplete: true,
        isCoherent: true,
        isDidactic: true,
        hasGoodStructure: true,
        isDeepEnough: true,
        issues: [],
        suggestions: undefined
      };
    }
  }

  private createRobustPrompt(params: {
    question: string;
    studyProfile: string;
    context: string;
    subjectsList: string;
    goalContext: string;
    knowledgeContext: string;
    webContext: string;
    hasPersonalKnowledge: boolean;
    selectedGoal?: any;
  }): string {
    const { question, studyProfile, context, subjectsList, goalContext, knowledgeContext, webContext, hasPersonalKnowledge } = params;

    // Sistema inteligente: usa base de conhecimento OU busca na internet
    if (hasPersonalKnowledge && knowledgeContext.length > 200) {
      // TEM informa√ß√£o suficiente na base pessoal
      return `Voc√™ √© um assistente de estudos expert. Responda usando as informa√ß√µes da base de conhecimento do estudante.

${knowledgeContext}

PERGUNTA: ${question}

FORMATO DA RESPOSTA:
- Use Markdown para formata√ß√£o (t√≠tulos, listas, tabelas, negrito, etc.)
- Organize em se√ß√µes claras com cabe√ßalhos (##)
- Use tabelas quando apropriado
- Destaque pontos importantes com **negrito**
- Use listas numeradas ou com bullet points
- Cite trechos espec√≠ficos do material quando relevante

Responda de forma completa, did√°tica e bem estruturada usando todo o conhecimento dispon√≠vel.`;
    } else {
      // N√ÉO tem informa√ß√£o suficiente - informa + busca internet
      return `Voc√™ √© um assistante de estudos. O estudante perguntou: ${question}

${hasPersonalKnowledge ? `## Base de Conhecimento Consultada\n${knowledgeContext}` : '## Base de Conhecimento\nNenhuma informa√ß√£o relevante encontrada nos documentos pessoais.'}

${webContext ? `## Informa√ß√µes Complementares\n${webContext}` : ''}

FORMATO DA RESPOSTA:
- Use Markdown para formata√ß√£o (t√≠tulos, listas, tabelas, negrito)
- Se h√° informa√ß√£o limitada na base pessoal, informe brevemente
- Use informa√ß√µes da internet para complementar
- Cite fontes quando usar informa√ß√µes externas
- Organize com cabe√ßalhos e listas
- Destaque pontos importantes

Responda de forma √∫til, completa e bem estruturada.`;
    }
  }

  async analyzeStudyMaterial(content: string, type: string): Promise<{
    summary: string;
    keyTopics: string[];
    difficulty: string;
  }> {
    const prompt = `Analyze the following study material and provide:
1. A brief summary (2-3 sentences)
2. Key topics covered (3-5 main topics)
3. Difficulty level (easy, medium, hard)

Material Type: ${type}
Content: ${content.substring(0, 2000)}...

Respond with JSON in this format:
{
  "summary": "Brief summary here",
  "keyTopics": ["Topic 1", "Topic 2", "Topic 3"],
  "difficulty": "medium"
}`;

    try {
      const response = await openai.chat.completions.create({
        model: "deepseek/deepseek-r1",
        messages: [
          {
            role: "user",
            content: prompt
          }
        ],
        temperature: 0.3,
        max_tokens: 500,
      });

      const text = response.choices[0]?.message?.content;
      if (!text) {
        throw new Error("No response from AI");
      }
      
      // Clean JSON response
      const jsonMatch = text.match(/\{[\s\S]*\}/);
      if (!jsonMatch) {
        throw new Error("No valid JSON found in response");
      }
      
      return JSON.parse(jsonMatch[0]);
    } catch (error) {
      console.error("Error analyzing material:", error);
      return {
        summary: "Unable to analyze material content.",
        keyTopics: [],
        difficulty: "medium"
      };
    }
  }

  async extractTextFromFile(filePath: string): Promise<string> {
    try {
      const ext = path.extname(filePath).toLowerCase();
      
      // Handle text files
      if (ext === '.txt' || ext === '.md') {
        return fs.readFileSync(filePath, 'utf-8');
      }
      
      // Handle PDF files
      if (ext === '.pdf') {
        const { default: pdfParse } = await import('pdf-parse');
        const buffer = fs.readFileSync(filePath);
        const data = await pdfParse(buffer);
        console.log(`üìÑ PDF extra√≠do: ${data.text.length} caracteres de conte√∫do`);
        return data.text || "N√£o foi poss√≠vel extrair texto do PDF";
      }
      
      // Handle DOCX files
      if (ext === '.docx') {
        const buffer = fs.readFileSync(filePath);
        const result = await mammoth.extractRawText({ buffer });
        console.log(`üìÑ DOCX extra√≠do: ${result.value.length} caracteres de conte√∫do`);
        return result.value || "N√£o foi poss√≠vel extrair texto do DOCX";
      }
      
      // Handle DOC files (limited support)
      if (ext === '.doc') {
        console.log('‚ö†Ô∏è Arquivos .DOC t√™m suporte limitado. Recomenda-se converter para .DOCX');
        return "Arquivos .DOC t√™m suporte limitado. Por favor, converta para .DOCX para melhor extra√ß√£o de texto.";
      }
      
      // For other file types, return error message
      return `Tipo de arquivo ${ext} n√£o suportado. Tipos suportados: PDF, DOCX, TXT, MD.`;
    } catch (error) {
      console.error("Error extracting text from file:", error);
      throw new Error("Failed to extract text from file");
    }
  }

  /**
   * NOVO: Migra documento para o sistema RAG/Pinecone quando criado
   */
  async migrateToRAG(document: any, userId: string) {
    try {
      await ragService.addDocumentToRAG(
        document.id,
        document.title,
        document.content || '',
        userId,
        document.category || 'Geral'
      );
      console.log(`üìö Documento migrado para RAG: ${document.title}`);
    } catch (error) {
      console.error('‚ùå Erro ao migrar para RAG:', error);
    }
  }

  async generateFlashcards(request: FlashcardGenerationRequest): Promise<GeneratedFlashcard[]> {
    const { content, studyProfile, subject, count } = request;

    // Customize prompt based on study profile
    const profileStrategies = {
      disciplined: "Crie flashcards desafiadores que exigem compreens√£o profunda e aplica√ß√£o de conceitos. Foque em an√°lise e resolu√ß√£o de problemas.",
      undisciplined: "Crie flashcards envolventes e pr√°ticos com aplica√ß√µes do mundo real. Use formatos variados para manter o interesse e motiva√ß√£o.",
      average: "Crie um mix equilibrado de flashcards te√≥ricos e pr√°ticos com explica√ß√µes claras para refor√ßar o aprendizado."
    };

    const strategy = profileStrategies[studyProfile as keyof typeof profileStrategies] || profileStrategies.average;

    const prompt = `Voc√™ √© um especialista em educa√ß√£o criando flashcards personalizados e bem formatados em portugu√™s.

${subject ? `Mat√©ria: ${subject}` : ''}
Perfil de Estudo: ${studyProfile}
Estrat√©gia: ${strategy}

CONTE√öDO DE ESTUDO QUE DEVE SER USADO PARA CRIAR OS FLASHCARDS:
---
${content.substring(0, 6000)}${content.length > 6000 ? '...\n[conte√∫do continua]' : ''}
---

INSTRU√á√ïES IMPORTANTES:
- Os flashcards DEVEM ser baseados EXCLUSIVAMENTE no conte√∫do fornecido acima
- N√ÉO crie flashcards gen√©ricos ou de conhecimento geral
- Extraia conceitos, defini√ß√µes, fatos e explica√ß√µes diretamente do texto
- Se o conte√∫do cont√©m exemplos, inclua-os nos flashcards
- Identifique termos t√©cnicos, nomes importantes, datas, processos explicados no texto

FORMATA√á√ÉO OBRIGAT√ìRIA (use Markdown):
- Use **negrito** para destacar termos importantes
- Use *it√°lico* para √™nfase
- Use \`c√≥digo\` para termos t√©cnicos ou conceitos espec√≠ficos
- Use ### para subt√≠tulos quando apropriado
- Use listas numeradas (1. 2. 3.) ou com bullets (- ) para organizar informa√ß√µes
- Use > para cita√ß√µes ou destaques importantes
- Use tabelas quando houver dados comparativos:
  | Conceito | Defini√ß√£o |
  |----------|-----------|
  | Termo    | Explica√ß√£o |
- Use quebras de linha duplas para separar par√°grafos
- Use --- para separadores visuais quando necess√°rio

EXEMPLOS DE FORMATA√á√ÉO:
**Front:** O que √© **Direito Constitucional**?

**Back:** 
### Defini√ß√£o
O **Direito Constitucional** √© o ramo do direito que estuda:

1. **Constitui√ß√£o** - norma fundamental do Estado
2. **Organiza√ß√£o dos poderes** - estrutura governamental  
3. **Direitos fundamentais** - garantias dos cidad√£os

> √â considerado o *"direito dos direitos"* por ser hierarquicamente superior.

---
**Caracter√≠sticas principais:**
- Supremacia constitucional
- Rigidez constitucional
- Controle de constitucionalidade

Crie exatamente ${count} flashcards baseados no conte√∫do fornecido. Cada flashcard deve:
1. Estar DIRETAMENTE relacionado ao conte√∫do fornecido acima
2. Ser adequado para um estudante com perfil ${studyProfile}
3. Ter uma pergunta clara na frente (front) extra√≠da do conte√∫do
4. Ter uma resposta completa e educativa no verso (back) com formata√ß√£o markdown
5. Estar em portugu√™s
6. Usar formata√ß√£o rica para melhor apresenta√ß√£o
7. Referenciar informa√ß√µes espec√≠ficas do material fornecido

Responda com um objeto JSON contendo um array de flashcards no seguinte formato:
{
  "flashcards": [
    {
      "front": "Pergunta ou conceito aqui (pode usar markdown b√°sico)",
      "back": "Resposta detalhada com **formata√ß√£o markdown rica** incluindo:\\n\\n### Subt√≠tulos\\n\\n1. Listas numeradas\\n- Bullets\\n\\n> Cita√ß√µes importantes\\n\\n| Tabela | Quando necess√°rio |\\n|--------|-------------------|\\n| Item   | Descri√ß√£o        |"
    }
  ]
}`;

    try {
      const response = await openai.chat.completions.create({
        model: "deepseek/deepseek-r1",
        messages: [
          {
            role: "user",
            content: prompt
          }
        ],
        temperature: 0.7,
        max_tokens: 2000,
      });

      const text = response.choices[0]?.message?.content;
      if (!text) {
        throw new Error("No response from AI");
      }
      
      // Clean JSON response
      const jsonMatch = text.match(/\{[\s\S]*\}/);
      if (!jsonMatch) {
        throw new Error("No valid JSON found in response");
      }
      
      const parsed = JSON.parse(jsonMatch[0]);
      return parsed.flashcards || [];
    } catch (error) {
      console.error("Error generating flashcards:", error);
      throw new Error("Failed to generate flashcards: " + (error as Error).message);
    }
  }
}

export const aiService = new AIService();