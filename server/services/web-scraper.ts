import { embeddingsService } from './embeddings';
import { pineconeService } from './pinecone';
import fetch from 'node-fetch';
import * as cheerio from 'cheerio';

interface ScrapedPage {
  url: string;
  title: string;
  content: string;
  links: string[];
}

interface ScrapingOptions {
  maxPages?: number;
  maxDepth?: number;
  includeExternalLinks?: boolean;
  delay?: number;
}

export class WebScraperService {
  private visitedUrls = new Set<string>();
  private baseUrl = '';
  
  constructor() {}

  /**
   * Escaneia uma URL completa incluindo suas pagina√ß√µes
   */
  async scrapeWebsite(
    url: string, 
    searchTypes: string[],
    siteId: string,
    options: ScrapingOptions = {}
  ): Promise<void> {
    try {
      console.log(`üï∑Ô∏è Iniciando scraping de: ${url}`);
      
      const {
        maxPages = 50,
        maxDepth = 3,
        includeExternalLinks = false,
        delay = 1000
      } = options;

      this.baseUrl = new URL(url).origin;
      this.visitedUrls.clear();

      // Fazer scraping real da URL
      const scrapedPages = await this.realScrapeWithPagination(url, maxPages, maxDepth);
      
      console.log(`üìÑ Coletadas ${scrapedPages.length} p√°ginas para processamento`);

      // Processar cada p√°gina coletada
      for (let index = 0; index < scrapedPages.length; index++) {
        const page = scrapedPages[index];
        console.log(`üìù Processando p√°gina ${index + 1}/${scrapedPages.length}: ${page.title}`);
        
        // Quebrar conte√∫do em chunks
        const chunks = this.chunkContent(page.content, 1000);
        
        // Preparar metadados
        const metadata = {
          userId: 'admin_scraped', // Namespace para conte√∫do scrapado
          title: page.title,
          category: 'website',
          siteId: siteId,
          sourceUrl: page.url,
          searchTypes: searchTypes.join(','),
          scrapedAt: new Date().toISOString()
        };

        // Enviar para Pinecone
        await pineconeService.upsertDocument(
          `scraped_${siteId}_${index}`,
          chunks,
          metadata
        );

        console.log(`‚úÖ P√°gina processada: ${page.title}`);
        
        // Pausa entre processamentos
        await new Promise(resolve => setTimeout(resolve, delay));
      }

      console.log(`üéâ Scraping completo! ${scrapedPages.length} p√°ginas processadas e enviadas para Pinecone`);
      
    } catch (error: any) {
      console.error('‚ùå Erro durante scraping:', error);
      throw error;
    }
  }

  /**
   * Scraping real com pagina√ß√£o usando fetch e cheerio
   */
  private async realScrapeWithPagination(url: string, maxPages: number, maxDepth: number): Promise<ScrapedPage[]> {
    const pages: ScrapedPage[] = [];
    const urlsToVisit: { url: string; depth: number }[] = [{ url, depth: 0 }];
    
    while (urlsToVisit.length > 0 && pages.length < maxPages) {
      const { url: currentUrl, depth } = urlsToVisit.shift()!;
      
      if (this.visitedUrls.has(currentUrl) || depth > maxDepth) {
        continue;
      }

      this.visitedUrls.add(currentUrl);
      
      try {
        // Fazer requisi√ß√£o HTTP real e extra√ß√£o de conte√∫do
        const page = await this.realExtractPageContent(currentUrl);
        if (page.content.trim()) { // S√≥ adicionar se tiver conte√∫do
          pages.push(page);
        }
        
        // Se n√£o atingiu a profundidade m√°xima, adicionar links encontrados
        if (depth < maxDepth) {
          for (const link of page.links) {
            if (!this.visitedUrls.has(link) && this.isValidUrl(link)) {
              urlsToVisit.push({ url: link, depth: depth + 1 });
            }
          }
        }
        
        console.log(`üìä Coletada: ${page.title} (${pages.length}/${maxPages})`);
        
        // Pausa entre requisi√ß√µes para n√£o sobrecarregar o servidor
        await new Promise(resolve => setTimeout(resolve, 500));
        
      } catch (error: any) {
        console.warn(`‚ö†Ô∏è Erro ao processar ${currentUrl}:`, error.message);
      }
    }
    
    return pages;
  }

  /**
   * Vers√£o mock do scraping com pagina√ß√£o
   * Em produ√ß√£o, seria substitu√≠do por Puppeteer real
   */
  private async mockScrapeWithPagination(url: string, maxPages: number, maxDepth: number): Promise<ScrapedPage[]> {
    const pages: ScrapedPage[] = [];
    const urlsToVisit: { url: string; depth: number }[] = [{ url, depth: 0 }];
    
    while (urlsToVisit.length > 0 && pages.length < maxPages) {
      const { url: currentUrl, depth } = urlsToVisit.shift()!;
      
      if (this.visitedUrls.has(currentUrl) || depth > maxDepth) {
        continue;
      }

      this.visitedUrls.add(currentUrl);
      
      try {
        // Simular requisi√ß√£o HTTP e extra√ß√£o de conte√∫do
        const page = await this.mockExtractPageContent(currentUrl);
        pages.push(page);
        
        // Se n√£o atingiu a profundidade m√°xima, adicionar links encontrados
        if (depth < maxDepth) {
          for (const link of page.links) {
            if (!this.visitedUrls.has(link)) {
              urlsToVisit.push({ url: link, depth: depth + 1 });
            }
          }
        }
        
        console.log(`üìä Coletada: ${page.title} (${pages.length}/${maxPages})`);
        
      } catch (error: any) {
        console.warn(`‚ö†Ô∏è Erro ao processar ${currentUrl}:`, error.message);
      }
    }
    
    return pages;
  }

  /**
   * Mock de extra√ß√£o de conte√∫do da p√°gina
   * Em produ√ß√£o, usaria Puppeteer, Cheerio ou similar
   */
  private async mockExtractPageContent(url: string): Promise<ScrapedPage> {
    // Simular delay de rede
    await new Promise(resolve => setTimeout(resolve, 200));
    
    // Determinar tipo de conte√∫do baseado na URL
    const urlLower = url.toLowerCase();
    let content = '';
    let title = '';
    let links: string[] = [];
    
    if (urlLower.includes('cebraspe') || urlLower.includes('concurso')) {
      title = `Concurso P√∫blico - ${new URL(url).pathname}`;
      content = `
        Informa√ß√µes sobre concurso p√∫blico organizado pelo Cebraspe.
        
        Detalhes do Concurso:
        - √ìrg√£o: Secretaria de Educa√ß√£o
        - Cargo: Professor de Ensino Fundamental
        - Vagas: 100 vagas
        - Sal√°rio: R$ 3.500,00 a R$ 5.200,00
        - Inscri√ß√µes: De 01/10/2025 a 30/10/2025
        - Prova: 15/12/2025
        
        Requisitos:
        - Ensino Superior Completo em Pedagogia ou Licenciatura
        - Experi√™ncia m√≠nima de 2 anos (desej√°vel)
        
        Etapas do Concurso:
        1. Prova Objetiva (eliminat√≥ria e classificat√≥ria)
        2. Prova de T√≠tulos (classificat√≥ria)
        3. Exame M√©dico (eliminat√≥rio)
        
        Conte√∫do Program√°tico:
        - L√≠ngua Portuguesa
        - Matem√°tica
        - Conhecimentos Pedag√≥gicos
        - Conhecimentos Espec√≠ficos do Cargo
        
        Como se inscrever:
        Acesse o site oficial e preencha o formul√°rio de inscri√ß√£o.
        Taxa de inscri√ß√£o: R$ 85,00
      `;
      
      links = [
        `${this.baseUrl}/edital-completo`,
        `${this.baseUrl}/cronograma`,
        `${this.baseUrl}/local-prova`,
        `${this.baseUrl}/resultado`
      ];
      
    } else if (urlLower.includes('vestibular') || urlLower.includes('enem')) {
      title = `Vestibular - ${new URL(url).pathname}`;
      content = `
        Processo Seletivo para Ensino Superior - Vestibular 2025
        
        Informa√ß√µes Gerais:
        - Institui√ß√£o: Universidade Federal de Exemplo
        - Modalidade: Vestibular + ENEM
        - Vagas Oferecidas: 2.500 vagas
        - Cursos: 45 cursos de gradua√ß√£o
        
        Cronograma:
        - Inscri√ß√µes: 15/08/2025 a 15/09/2025
        - Primeira Fase: 20/10/2025
        - Segunda Fase: 25/11/2025
        - Resultado: 15/01/2026
        
        Modalidades de Ingresso:
        - Ampla Concorr√™ncia: 60%
        - Cotas Sociais: 25%
        - Cotas √âtnico-Raciais: 15%
        
        Cursos Mais Concorridos:
        - Medicina (rela√ß√£o 50 candidatos/vaga)
        - Direito (rela√ß√£o 35 candidatos/vaga)
        - Engenharia (rela√ß√£o 25 candidatos/vaga)
        
        Disciplinas da Prova:
        - Reda√ß√£o
        - L√≠ngua Portuguesa e Literatura
        - Matem√°tica
        - Hist√≥ria e Geografia
        - F√≠sica, Qu√≠mica e Biologia
        - L√≠ngua Estrangeira (Ingl√™s ou Espanhol)
      `;
      
      links = [
        `${this.baseUrl}/cursos-oferecidos`,
        `${this.baseUrl}/manual-candidato`,
        `${this.baseUrl}/simulados`,
        `${this.baseUrl}/biblioteca-virtual`
      ];
      
    } else if (urlLower.includes('escola') || urlLower.includes('educacao')) {
      title = `Educa√ß√£o B√°sica - ${new URL(url).pathname}`;
      content = `
        Sistema de Ensino Fundamental e M√©dio
        
        Estrutura Educacional:
        - Ensino Fundamental I (1¬∫ ao 5¬∫ ano)
        - Ensino Fundamental II (6¬∫ ao 9¬∫ ano)
        - Ensino M√©dio (1¬∫ ao 3¬∫ ano)
        - Educa√ß√£o de Jovens e Adultos (EJA)
        
        Metodologia:
        - Ensino h√≠brido com tecnologia
        - Projetos interdisciplinares
        - Acompanhamento pedag√≥gico individual
        - Prepara√ß√£o para vestibulares e ENEM
        
        Atividades Extracurriculares:
        - Esportes (futebol, v√¥lei, basquete)
        - Artes (teatro, m√∫sica, dan√ßa)
        - Idiomas (ingl√™s, espanhol)
        - Rob√≥tica e programa√ß√£o
        
        Avalia√ß√£o e Acompanhamento:
        - Sistema de avalia√ß√£o continuada
        - Reuni√µes pedag√≥gicas trimestrais
        - Portal do aluno para acompanhamento
        - Orienta√ß√£o vocacional no ensino m√©dio
        
        Recursos e Infraestrutura:
        - Laborat√≥rios de ci√™ncias
        - Biblioteca digital
        - Quadras esportivas
        - Audit√≥rio multim√≠dia
      `;
      
      links = [
        `${this.baseUrl}/projeto-pedagogico`,
        `${this.baseUrl}/calendario-escolar`,
        `${this.baseUrl}/eventos`,
        `${this.baseUrl}/matriculas`
      ];
      
    } else {
      title = `P√°gina Web - ${new URL(url).hostname}`;
      content = `
        Conte√∫do gen√©rico extra√≠do da p√°gina web.
        URL: ${url}
        
        Esta √© uma p√°gina que foi processada pelo sistema de scraping.
        O conte√∫do real seria extra√≠do usando ferramentas como Puppeteer
        ou Cheerio em um ambiente de produ√ß√£o.
        
        Informa√ß√µes que seriam coletadas:
        - Texto principal da p√°gina
        - T√≠tulos e subt√≠tulos
        - Links internos e externos
        - Metadados relevantes
        - Estrutura de navega√ß√£o
        
        Este conte√∫do mock permite testar o sistema de embeddings
        e busca sem depender de scraping real.
      `;
      
      links = [
        `${this.baseUrl}/sobre`,
        `${this.baseUrl}/contato`,
        `${this.baseUrl}/servicos`
      ];
    }
    
    return {
      url,
      title,
      content: content.trim(),
      links: links.filter(link => !this.visitedUrls.has(link))
    };
  }

  /**
   * Extra√ß√£o real de conte√∫do da p√°gina usando fetch e cheerio
   */
  private async realExtractPageContent(url: string): Promise<ScrapedPage> {
    try {
      console.log(`üîç Fazendo scraping de: ${url}`);
      
      // Fazer requisi√ß√£o HTTP com timeout
      const controller = new AbortController();
      const timeoutId = setTimeout(() => controller.abort(), 10000);
      
      const response = await fetch(url, {
        headers: {
          'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        },
        signal: controller.signal
      });
      
      clearTimeout(timeoutId);

      if (!response.ok) {
        throw new Error(`HTTP ${response.status}: ${response.statusText}`);
      }

      const html = await response.text();
      const $ = cheerio.load(html);

      // Remover scripts, styles e outros elementos n√£o desejados
      $('script, style, nav, header, footer, .menu, .navigation').remove();

      // Extrair t√≠tulo
      let title = $('title').text().trim() || $('h1').first().text().trim() || 'P√°gina sem t√≠tulo';

      // Extrair conte√∫do principal
      let content = '';
      
      // Tentar extrair conte√∫do de containers principais
      const contentSelectors = [
        'main',
        '.content',
        '.main-content', 
        '#content',
        'article',
        '.post',
        '.entry-content',
        'body'
      ];

      for (const selector of contentSelectors) {
        const element = $(selector);
        if (element.length > 0) {
          content = element.text().trim();
          if (content.length > 100) { // Se encontrou conte√∫do substancial, usar este
            break;
          }
        }
      }

      // Se n√£o encontrou conte√∫do nos seletores espec√≠ficos, usar todo o body
      if (!content || content.length < 100) {
        content = $('body').text().trim();
      }

      // Limpar conte√∫do (remover quebras de linha excessivas, espa√ßos)
      content = content.replace(/\s+/g, ' ').trim();

      // Extrair links da mesma origem
      const links: string[] = [];
      $('a[href]').each((_, element) => {
        const href = $(element).attr('href');
        if (href) {
          const absoluteUrl = this.resolveUrl(href, url);
          if (absoluteUrl && this.isSameOrigin(absoluteUrl, url)) {
            links.push(absoluteUrl);
          }
        }
      });

      // Remover duplicatas dos links
      const uniqueLinks = Array.from(new Set(links));

      console.log(`‚úÖ Coletado: ${title} - ${content.length} caracteres, ${uniqueLinks.length} links`);

      return {
        url,
        title,
        content,
        links: uniqueLinks.slice(0, 20) // Limitar a 20 links por p√°gina
      };

    } catch (error: any) {
      console.warn(`‚ö†Ô∏è Erro ao fazer scraping de ${url}:`, error.message);
      return {
        url,
        title: `Erro ao carregar: ${url}`,
        content: '',
        links: []
      };
    }
  }

  /**
   * Resolve URL relativa para absoluta
   */
  private resolveUrl(href: string, baseUrl: string): string | null {
    try {
      if (href.startsWith('http://') || href.startsWith('https://')) {
        return href;
      }
      return new URL(href, baseUrl).href;
    } catch {
      return null;
    }
  }

  /**
   * Verifica se duas URLs s√£o da mesma origem
   */
  private isSameOrigin(url1: string, url2: string): boolean {
    try {
      const origin1 = new URL(url1).origin;
      const origin2 = new URL(url2).origin;
      return origin1 === origin2;
    } catch {
      return false;
    }
  }

  /**
   * Valida se uma URL √© v√°lida e deve ser processada
   */
  private isValidUrl(url: string): boolean {
    try {
      const parsedUrl = new URL(url);
      // Filtrar apenas HTTP/HTTPS
      if (!['http:', 'https:'].includes(parsedUrl.protocol)) {
        return false;
      }
      // Filtrar arquivos que n√£o queremos processar
      const pathname = parsedUrl.pathname.toLowerCase();
      const excludeExtensions = ['.pdf', '.doc', '.docx', '.xls', '.xlsx', '.zip', '.rar', '.jpg', '.jpeg', '.png', '.gif'];
      if (excludeExtensions.some(ext => pathname.endsWith(ext))) {
        return false;
      }
      return true;
    } catch {
      return false;
    }
  }

  /**
   * Quebra conte√∫do em chunks para processamento
   */
  private chunkContent(content: string, chunkSize: number = 1000): { content: string; chunkIndex: number }[] {
    const words = content.split(/\s+/);
    const chunks: { content: string; chunkIndex: number }[] = [];
    
    for (let i = 0; i < words.length; i += chunkSize) {
      const chunk = words.slice(i, i + chunkSize).join(' ');
      chunks.push({
        content: chunk,
        chunkIndex: chunks.length
      });
    }
    
    return chunks.length > 0 ? chunks : [{ content, chunkIndex: 0 }];
  }

  /**
   * Busca conte√∫do scrapado por tipo
   */
  async searchScrapedContent(
    query: string,
    searchTypes: string[],
    options: {
      topK?: number;
      minSimilarity?: number;
    } = {}
  ): Promise<any[]> {
    try {
      const { topK = 5, minSimilarity = 0.3 } = options;
      
      console.log(`üîç Buscando em conte√∫do scrapado: "${query}"`);
      console.log(`üìã Tipos de busca: ${searchTypes.join(', ')}`);
      
      // Buscar no Pinecone usando o namespace de admin
      const results = await pineconeService.searchSimilarContent(
        query,
        'admin_scraped',
        {
          topK,
          category: 'website',
          minSimilarity
        }
      );
      
      // Filtrar por tipos de busca
      const filteredResults = results.filter((result: any) => {
        const resultTypes = result.metadata?.searchTypes?.split(',') || [];
        return searchTypes.some(type => resultTypes.includes(type));
      });
      
      console.log(`üìä Encontrados ${filteredResults.length} resultados em conte√∫do scrapado`);
      
      return filteredResults.map((result: any) => ({
        id: `scraped_${Date.now()}_${Math.random()}`,
        name: result.title,
        url: result.metadata?.sourceUrl || '',
        description: result.content.substring(0, 200) + '...',
        fullContent: result.content,
        score: result.similarity,
        source: 'scraped'
      }));
      
    } catch (error) {
      console.error('‚ùå Erro na busca de conte√∫do scrapado:', error);
      return [];
    }
  }
}

export const webScraperService = new WebScraperService();