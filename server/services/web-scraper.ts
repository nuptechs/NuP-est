import { embeddingsService } from './embeddings';
import { pineconeService } from './pinecone';
import fetch from 'node-fetch';
import * as cheerio from 'cheerio';
// Browser rendering removido - n√£o funciona em ambientes containerizados como Replit

interface ScrapedPage {
  url: string;
  title: string;
  content: string;
  links: string[];
}

interface ScrapingOptions {
  maxPages?: number;
  maxDepth?: number;
  includeExternalLinks?: boolean;
  delay?: number;
}

export class WebScraperService {
  private visitedUrls = new Set<string>();
  private baseUrl = '';
  
  constructor() {}

  /**
   * Escaneia uma URL completa incluindo suas pagina√ß√µes
   */
  async scrapeWebsite(
    url: string, 
    searchTypes: string[],
    siteId: string,
    options: ScrapingOptions = {}
  ): Promise<void> {
    try {
      console.log(`üï∑Ô∏è Iniciando scraping completo de: ${url}`);
      
      const {
        maxPages = 50,
        maxDepth = 3,
        includeExternalLinks = false,
        delay = 1000
      } = options;

      this.baseUrl = new URL(url).origin;
      this.visitedUrls.clear();

      // Validar se a URL √© acess√≠vel antes de come√ßar
      await this.validateUrl(url);

      // Fazer scraping real da URL
      console.log(`üåê Coletando p√°ginas com par√¢metros: maxPages=${maxPages}, maxDepth=${maxDepth}`);
      const scrapedPages = await this.realScrapeWithPagination(url, maxPages, maxDepth);
      
      if (scrapedPages.length === 0) {
        throw new Error('Nenhuma p√°gina foi coletada. Verifique se a URL est√° acess√≠vel.');
      }
      
      console.log(`üìÑ Coletadas ${scrapedPages.length} p√°ginas para processamento`);

      // Processar cada p√°gina coletada
      let processedCount = 0;
      for (let index = 0; index < scrapedPages.length; index++) {
        const page = scrapedPages[index];
        console.log(`üìù Processando p√°gina ${index + 1}/${scrapedPages.length}: ${page.title}`);
        
        try {
          // Quebrar conte√∫do em chunks
          const chunks = this.chunkContent(page.content, 1000);
          
          if (chunks.length === 0) {
            console.warn(`‚ö†Ô∏è P√°gina sem conte√∫do v√°lido: ${page.url}`);
            continue;
          }
          
          // Preparar metadados
          const metadata = {
            userId: 'admin_scraped', // Namespace para conte√∫do scrapado
            title: page.title,
            category: 'website',
            siteId: siteId,
            sourceUrl: page.url,
            searchTypes: searchTypes.join(','),
            scrapedAt: new Date().toISOString()
          };

          // Enviar para Pinecone com retry
          await this.sendToPineconeWithRetry(
            `scraped_${siteId}_${index}`,
            chunks,
            metadata
          );

          processedCount++;
          console.log(`‚úÖ P√°gina processada: ${page.title} (${processedCount}/${scrapedPages.length})`);
          
        } catch (pageError: any) {
          console.error(`‚ùå Erro ao processar p√°gina ${page.url}:`, pageError.message);
          // Continuar com a pr√≥xima p√°gina ao inv√©s de parar
        }
        
        // Pausa entre processamentos
        await new Promise(resolve => setTimeout(resolve, delay));
      }

      if (processedCount === 0) {
        throw new Error('Nenhuma p√°gina foi processada com sucesso.');
      }

      console.log(`üéâ Scraping conclu√≠do com sucesso! ${processedCount}/${scrapedPages.length} p√°ginas processadas e enviadas para Pinecone`);
      
    } catch (error: any) {
      console.error('‚ùå Erro cr√≠tico durante scraping:', error);
      throw new Error(`Falha no scraping de ${url}: ${error.message}`);
    }
  }

  /**
   * Scraping real com pagina√ß√£o usando fetch e cheerio
   */
  private async realScrapeWithPagination(url: string, maxPages: number, maxDepth: number): Promise<ScrapedPage[]> {
    const pages: ScrapedPage[] = [];
    const urlsToVisit: { url: string; depth: number }[] = [{ url, depth: 0 }];
    
    while (urlsToVisit.length > 0 && pages.length < maxPages) {
      const { url: currentUrl, depth } = urlsToVisit.shift()!;
      
      if (this.visitedUrls.has(currentUrl) || depth > maxDepth) {
        continue;
      }

      this.visitedUrls.add(currentUrl);
      
      try {
        // Fazer requisi√ß√£o HTTP real e extra√ß√£o de conte√∫do
        const page = await this.realExtractPageContent(currentUrl);
        if (page.content.trim()) { // S√≥ adicionar se tiver conte√∫do
          pages.push(page);
        }
        
        // Se n√£o atingiu a profundidade m√°xima, adicionar links encontrados
        if (depth < maxDepth) {
          for (const link of page.links) {
            if (!this.visitedUrls.has(link) && this.isValidUrl(link)) {
              urlsToVisit.push({ url: link, depth: depth + 1 });
            }
          }
        }
        
        console.log(`üìä Coletada: ${page.title} (${pages.length}/${maxPages})`);
        
        // Pausa entre requisi√ß√µes para n√£o sobrecarregar o servidor
        await new Promise(resolve => setTimeout(resolve, 500));
        
      } catch (error: any) {
        console.warn(`‚ö†Ô∏è Erro ao processar ${currentUrl}:`, error.message);
      }
    }
    
    return pages;
  }

  /**
   * Vers√£o mock do scraping com pagina√ß√£o
   * Em produ√ß√£o, seria substitu√≠do por Puppeteer real
   */
  private async mockScrapeWithPagination(url: string, maxPages: number, maxDepth: number): Promise<ScrapedPage[]> {
    const pages: ScrapedPage[] = [];
    const urlsToVisit: { url: string; depth: number }[] = [{ url, depth: 0 }];
    
    while (urlsToVisit.length > 0 && pages.length < maxPages) {
      const { url: currentUrl, depth } = urlsToVisit.shift()!;
      
      if (this.visitedUrls.has(currentUrl) || depth > maxDepth) {
        continue;
      }

      this.visitedUrls.add(currentUrl);
      
      try {
        // Fazer requisi√ß√£o HTTP real e extra√ß√£o de conte√∫do
        const page = await this.realExtractPageContent(currentUrl);
        if (page.content.trim()) { // S√≥ adicionar se tiver conte√∫do
          pages.push(page);
        }
        
        // Se n√£o atingiu a profundidade m√°xima, adicionar links encontrados
        if (depth < maxDepth) {
          for (const link of page.links) {
            if (!this.visitedUrls.has(link) && this.isValidUrl(link)) {
              urlsToVisit.push({ url: link, depth: depth + 1 });
            }
          }
        }
        
        console.log(`üìä Coletada: ${page.title} (${pages.length}/${maxPages})`);
        
      } catch (error: any) {
        console.warn(`‚ö†Ô∏è Erro ao processar ${currentUrl}:`, error.message);
      }
    }
    
    return pages;
  }

  /**
   * Mock de extra√ß√£o de conte√∫do da p√°gina
   * Em produ√ß√£o, usaria Puppeteer, Cheerio ou similar
   */
  private async mockExtractPageContent(url: string): Promise<ScrapedPage> {
    // Simular delay de rede
    await new Promise(resolve => setTimeout(resolve, 200));
    
    // Determinar tipo de conte√∫do baseado na URL
    const urlLower = url.toLowerCase();
    let content = '';
    let title = '';
    let links: string[] = [];
    
    if (urlLower.includes('cebraspe') || urlLower.includes('concurso')) {
      title = `Concurso P√∫blico - ${new URL(url).pathname}`;
      content = `
        Informa√ß√µes sobre concurso p√∫blico organizado pelo Cebraspe.
        
        Detalhes do Concurso:
        - √ìrg√£o: Secretaria de Educa√ß√£o
        - Cargo: Professor de Ensino Fundamental
        - Vagas: 100 vagas
        - Sal√°rio: R$ 3.500,00 a R$ 5.200,00
        - Inscri√ß√µes: De 01/10/2025 a 30/10/2025
        - Prova: 15/12/2025
        
        Requisitos:
        - Ensino Superior Completo em Pedagogia ou Licenciatura
        - Experi√™ncia m√≠nima de 2 anos (desej√°vel)
        
        Etapas do Concurso:
        1. Prova Objetiva (eliminat√≥ria e classificat√≥ria)
        2. Prova de T√≠tulos (classificat√≥ria)
        3. Exame M√©dico (eliminat√≥rio)
        
        Conte√∫do Program√°tico:
        - L√≠ngua Portuguesa
        - Matem√°tica
        - Conhecimentos Pedag√≥gicos
        - Conhecimentos Espec√≠ficos do Cargo
        
        Como se inscrever:
        Acesse o site oficial e preencha o formul√°rio de inscri√ß√£o.
        Taxa de inscri√ß√£o: R$ 85,00
      `;
      
      links = [
        `${this.baseUrl}/edital-completo`,
        `${this.baseUrl}/cronograma`,
        `${this.baseUrl}/local-prova`,
        `${this.baseUrl}/resultado`
      ];
      
    } else if (urlLower.includes('vestibular') || urlLower.includes('enem')) {
      title = `Vestibular - ${new URL(url).pathname}`;
      content = `
        Processo Seletivo para Ensino Superior - Vestibular 2025
        
        Informa√ß√µes Gerais:
        - Institui√ß√£o: Universidade Federal de Exemplo
        - Modalidade: Vestibular + ENEM
        - Vagas Oferecidas: 2.500 vagas
        - Cursos: 45 cursos de gradua√ß√£o
        
        Cronograma:
        - Inscri√ß√µes: 15/08/2025 a 15/09/2025
        - Primeira Fase: 20/10/2025
        - Segunda Fase: 25/11/2025
        - Resultado: 15/01/2026
        
        Modalidades de Ingresso:
        - Ampla Concorr√™ncia: 60%
        - Cotas Sociais: 25%
        - Cotas √âtnico-Raciais: 15%
        
        Cursos Mais Concorridos:
        - Medicina (rela√ß√£o 50 candidatos/vaga)
        - Direito (rela√ß√£o 35 candidatos/vaga)
        - Engenharia (rela√ß√£o 25 candidatos/vaga)
        
        Disciplinas da Prova:
        - Reda√ß√£o
        - L√≠ngua Portuguesa e Literatura
        - Matem√°tica
        - Hist√≥ria e Geografia
        - F√≠sica, Qu√≠mica e Biologia
        - L√≠ngua Estrangeira (Ingl√™s ou Espanhol)
      `;
      
      links = [
        `${this.baseUrl}/cursos-oferecidos`,
        `${this.baseUrl}/manual-candidato`,
        `${this.baseUrl}/simulados`,
        `${this.baseUrl}/biblioteca-virtual`
      ];
      
    } else if (urlLower.includes('escola') || urlLower.includes('educacao')) {
      title = `Educa√ß√£o B√°sica - ${new URL(url).pathname}`;
      content = `
        Sistema de Ensino Fundamental e M√©dio
        
        Estrutura Educacional:
        - Ensino Fundamental I (1¬∫ ao 5¬∫ ano)
        - Ensino Fundamental II (6¬∫ ao 9¬∫ ano)
        - Ensino M√©dio (1¬∫ ao 3¬∫ ano)
        - Educa√ß√£o de Jovens e Adultos (EJA)
        
        Metodologia:
        - Ensino h√≠brido com tecnologia
        - Projetos interdisciplinares
        - Acompanhamento pedag√≥gico individual
        - Prepara√ß√£o para vestibulares e ENEM
        
        Atividades Extracurriculares:
        - Esportes (futebol, v√¥lei, basquete)
        - Artes (teatro, m√∫sica, dan√ßa)
        - Idiomas (ingl√™s, espanhol)
        - Rob√≥tica e programa√ß√£o
        
        Avalia√ß√£o e Acompanhamento:
        - Sistema de avalia√ß√£o continuada
        - Reuni√µes pedag√≥gicas trimestrais
        - Portal do aluno para acompanhamento
        - Orienta√ß√£o vocacional no ensino m√©dio
        
        Recursos e Infraestrutura:
        - Laborat√≥rios de ci√™ncias
        - Biblioteca digital
        - Quadras esportivas
        - Audit√≥rio multim√≠dia
      `;
      
      links = [
        `${this.baseUrl}/projeto-pedagogico`,
        `${this.baseUrl}/calendario-escolar`,
        `${this.baseUrl}/eventos`,
        `${this.baseUrl}/matriculas`
      ];
      
    } else {
      title = `P√°gina Web - ${new URL(url).hostname}`;
      content = `
        Conte√∫do gen√©rico extra√≠do da p√°gina web.
        URL: ${url}
        
        Esta √© uma p√°gina que foi processada pelo sistema de scraping.
        O conte√∫do real seria extra√≠do usando ferramentas como Puppeteer
        ou Cheerio em um ambiente de produ√ß√£o.
        
        Informa√ß√µes que seriam coletadas:
        - Texto principal da p√°gina
        - T√≠tulos e subt√≠tulos
        - Links internos e externos
        - Metadados relevantes
        - Estrutura de navega√ß√£o
        
        Este conte√∫do mock permite testar o sistema de embeddings
        e busca sem depender de scraping real.
      `;
      
      links = [
        `${this.baseUrl}/sobre`,
        `${this.baseUrl}/contato`,
        `${this.baseUrl}/servicos`
      ];
    }
    
    return {
      url,
      title,
      content: content.trim(),
      links: links.filter(link => !this.visitedUrls.has(link))
    };
  }

  /**
   * Extra√ß√£o real de conte√∫do da p√°gina usando fetch e cheerio
   */
  private async realExtractPageContent(url: string): Promise<ScrapedPage> {
    try {
      console.log(`üîç Fazendo scraping de: ${url}`);
      
      // Fazer requisi√ß√£o HTTP com timeout aumentado
      const controller = new AbortController();
      const timeoutId = setTimeout(() => controller.abort(), 15000); // Timeout maior para sites lentos
      
      const response = await fetch(url, {
        headers: {
          'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
          'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
          'Accept-Language': 'pt-BR,pt;q=0.9,en;q=0.8',
          'Accept-Encoding': 'gzip, deflate, br',
          'DNT': '1',
          'Connection': 'keep-alive',
          'Upgrade-Insecure-Requests': '1'
        },
        signal: controller.signal
      });
      
      clearTimeout(timeoutId);

      if (!response.ok) {
        throw new Error(`HTTP ${response.status}: ${response.statusText}`);
      }

      const html = await response.text();
      const $ = cheerio.load(html);

      // Remover scripts, styles e outros elementos n√£o desejados
      $('script, style, nav, header, footer, .menu, .navigation').remove();

      // Extrair t√≠tulo
      let title = $('title').text().trim() || $('h1').first().text().trim() || 'P√°gina sem t√≠tulo';

      // Extrair conte√∫do principal com l√≥gica espec√≠fica para sites de concurso
      let content = '';
      
      let extraData: any = {};

      // Verificar se √© p√°gina do Cebraspe para usar extra√ß√£o espec√≠fica
      if (this.isCebraspeUrl(url)) {
        console.log('üèõÔ∏è URL do Cebraspe detectada - aplicando l√≥gica espec√≠fica');
        content = $('body').text().trim();
        
        // Processar dados espec√≠ficos do Cebraspe
        if (content.length > 100) {
          extraData = this.processCebraspeContent(content, url);
          console.log(`üìä Dados estruturados extra√≠dos: ${extraData.concursos?.length || 0} concursos`);
        }
      }
      
      // Se n√£o extraiu conte√∫do espec√≠fico, usar seletores gerais
      if (!content || content.length < 100) {
        const contentSelectors = [
          'main',
          '.content',
          '.main-content', 
          '#content',
          'article',
          '.post',
          '.entry-content',
          '.container',
          '.lista-concursos',
          '.concurso-item',
          'body'
        ];

        for (const selector of contentSelectors) {
          const element = $(selector);
          if (element.length > 0) {
            content = element.text().trim();
            if (content.length > 100) { // Se encontrou conte√∫do substancial, usar este
              break;
            }
          }
        }
      }

      // Se ainda n√£o encontrou conte√∫do, usar todo o body
      if (!content || content.length < 100) {
        content = $('body').text().trim();
      }

      // Se conte√∫do √© muito pequeno ou cont√©m JavaScript warning, tentar estrat√©gias alternativas
      if (!content || content.length < 50 || (content.includes('javascript') && content.length < 100)) {
        console.warn(`‚ö†Ô∏è Conte√∫do requer JavaScript - site n√£o √© compat√≠vel com scraping simples`);
        
        // Marcar como site incompat√≠vel em vez de tentar browser rendering
        return {
          url,
          title: `${title} (Requer JavaScript)`,
          content: `SITE_REQUIRES_JAVASCRIPT: Este site usa JavaScript din√¢mico e n√£o pode ser processado pelo sistema de scraping atual. URL: ${url}`,
          links: []
        };
      }

      // Limpar conte√∫do (remover quebras de linha excessivas, espa√ßos)
      content = content.replace(/\s+/g, ' ').trim();

      // Extrair links da mesma origem
      const links: string[] = [];
      $('a[href]').each((_: any, element: any) => {
        const href = $(element).attr('href');
        if (href) {
          const absoluteUrl = this.resolveUrl(href, url);
          if (absoluteUrl && this.isSameOrigin(absoluteUrl, url)) {
            links.push(absoluteUrl);
          }
        }
      });

      // Remover duplicatas dos links
      const uniqueLinks = Array.from(new Set(links));

      console.log(`‚úÖ Coletado: ${title} - ${content.length} caracteres, ${uniqueLinks.length} links`);

      return {
        url,
        title,
        content,
        links: uniqueLinks.slice(0, 20) // Limitar a 20 links por p√°gina
      };

    } catch (error: any) {
      console.warn(`‚ö†Ô∏è Erro ao fazer scraping de ${url}:`, error.message);
      return {
        url,
        title: `Erro ao carregar: ${url}`,
        content: '',
        links: []
      };
    }
  }

  /**
   * Resolve URL relativa para absoluta
   */
  private resolveUrl(href: string, baseUrl: string): string | null {
    try {
      if (href.startsWith('http://') || href.startsWith('https://')) {
        return href;
      }
      return new URL(href, baseUrl).href;
    } catch {
      return null;
    }
  }

  /**
   * Verifica se duas URLs s√£o da mesma origem
   */
  private isSameOrigin(url1: string, url2: string): boolean {
    try {
      const origin1 = new URL(url1).origin;
      const origin2 = new URL(url2).origin;
      return origin1 === origin2;
    } catch {
      return false;
    }
  }

  /**
   * Valida se uma URL √© v√°lida e deve ser processada
   */
  private isValidUrl(url: string): boolean {
    try {
      const parsedUrl = new URL(url);
      // Filtrar apenas HTTP/HTTPS
      if (!['http:', 'https:'].includes(parsedUrl.protocol)) {
        return false;
      }
      // Filtrar arquivos que n√£o queremos processar
      const pathname = parsedUrl.pathname.toLowerCase();
      const excludeExtensions = ['.pdf', '.doc', '.docx', '.xls', '.xlsx', '.zip', '.rar', '.jpg', '.jpeg', '.png', '.gif'];
      if (excludeExtensions.some(ext => pathname.endsWith(ext))) {
        return false;
      }
      return true;
    } catch {
      return false;
    }
  }

  /**
   * Valida se uma URL √© acess√≠vel antes de iniciar o scraping
   */
  private async validateUrl(url: string): Promise<void> {
    try {
      console.log(`üîó Validando URL: ${url}`);
      
      const controller = new AbortController();
      const timeoutId = setTimeout(() => controller.abort(), 10000);
      
      const response = await fetch(url, {
        method: 'HEAD', // Usar HEAD para validar sem baixar conte√∫do
        headers: {
          'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        },
        signal: controller.signal
      });
      
      clearTimeout(timeoutId);
      
      if (!response.ok) {
        throw new Error(`URL n√£o acess√≠vel: HTTP ${response.status} ${response.statusText}`);
      }
      
      console.log(`‚úÖ URL validada com sucesso: ${url}`);
      
    } catch (error: any) {
      if (error.name === 'AbortError') {
        throw new Error('Timeout ao acessar a URL. Verifique se o site est√° online.');
      }
      throw new Error(`Erro ao validar URL: ${error.message}`);
    }
  }

  /**
   * Extrai conte√∫do espec√≠fico de p√°ginas do Cebraspe
   * Inclui fallback para p√°ginas que exigem JavaScript
   */
  private extractCebraspeContent($: any, title: string): string {
    // Primeiro verificar se o conte√∫do √© apenas JavaScript warning
    const bodyText = $('body').text().trim();
    if (bodyText.includes('javascript') && bodyText.length < 100) {
      console.log('‚ö†Ô∏è P√°gina requer JavaScript - ser√° tratada pelo Puppeteer posteriormente');
      return ''; // Retornar vazio para ser processado pelo Puppeteer
    }
    let concursos: string[] = [];
    
    try {
      // Buscar por diferentes padr√µes de listagem de concursos
      const concursoSelectors = [
        '.lista-concursos .item',
        '.concurso-item',
        '.card-concurso',
        '.concurso',
        '.item-concurso',
        'div[class*="concurso"]',
        'li[class*="concurso"]',
        '.box-concurso',
        'article'
      ];
      
      for (const selector of concursoSelectors) {
        $(selector).each((_, element) => {
          const $item = $(element);
          
          // Extrair informa√ß√µes do concurso
          let nome = '';
          let vagas = '';
          let salario = '';
          let link = '';
          
          // Buscar nome do concurso em v√°rios seletores
          const nomeSelectors = ['h1', 'h2', 'h3', 'h4', '.titulo', '.nome', '.title', 'strong', '.concurso-nome'];
          for (const nomeSelector of nomeSelectors) {
            const nomeEl = $item.find(nomeSelector).first();
            if (nomeEl.length && nomeEl.text().trim()) {
              nome = nomeEl.text().trim();
              break;
            }
          }
          
          // Se n√£o encontrou nome espec√≠fico, usar texto principal
          if (!nome) {
            nome = $item.text().trim().split('\n')[0].substring(0, 100);
          }
          
          // Buscar vagas
          const vagasText = $item.text();
          const vagasMatch = vagasText.match(/(\d+(?:\.\d+)*)\s*vagas?/i);
          if (vagasMatch) {
            vagas = vagasMatch[0];
          }
          
          // Buscar sal√°rio
          const salarioMatch = vagasText.match(/(?:at√©\s*)?R\$\s*([\d.,]+)/i);
          if (salarioMatch) {
            salario = `At√© R$ ${salarioMatch[1]}`;
          }
          
          // Buscar link
          const linkEl = $item.find('a').first();
          if (linkEl.length) {
            link = linkEl.attr('href') || '';
          }
          
          // Se encontrou informa√ß√µes v√°lidas, adicionar √† lista
          if (nome && nome.length > 5) {
            let concursoInfo = `CONCURSO: ${nome}`;
            if (vagas) concursoInfo += ` | VAGAS: ${vagas}`;
            if (salario) concursoInfo += ` | SAL√ÅRIO: ${salario}`;
            if (link) concursoInfo += ` | LINK: ${link}`;
            
            concursos.push(concursoInfo);
          }
        });
        
        // Se encontrou concursos com este seletor, parar de buscar
        if (concursos.length > 0) {
          break;
        }
      }
      
      // Se n√£o encontrou via seletores espec√≠ficos, tentar buscar padr√µes no texto
      if (concursos.length === 0) {
        const bodyText = $('body').text();
        const lines = bodyText.split('\n').map(line => line.trim()).filter(line => line.length > 0);
        
        for (const line of lines) {
          // Buscar linhas que parecem ser nomes de concursos
          if (this.isLikelyContestName(line)) {
            const nextLines = lines.slice(lines.indexOf(line), lines.indexOf(line) + 5);
            let concursoInfo = `CONCURSO: ${line}`;
            
            // Buscar vagas e sal√°rio nas pr√≥ximas linhas
            for (const nextLine of nextLines) {
              const vagasMatch = nextLine.match(/(\d+(?:\.\d+)*)\s*vagas?/i);
              const salarioMatch = nextLine.match(/(?:at√©\s*)?R\$\s*([\d.,]+)/i);
              
              if (vagasMatch && !concursoInfo.includes('VAGAS:')) {
                concursoInfo += ` | VAGAS: ${vagasMatch[0]}`;
              }
              if (salarioMatch && !concursoInfo.includes('SAL√ÅRIO:')) {
                concursoInfo += ` | SAL√ÅRIO: At√© R$ ${salarioMatch[1]}`;
              }
            }
            
            concursos.push(concursoInfo);
          }
        }
      }
      
    } catch (error) {
      console.warn('Erro ao extrair conte√∫do espec√≠fico do Cebraspe:', error);
    }
    
    // Se encontrou concursos, retornar lista formatada
    if (concursos.length > 0) {
      return `P√ÅGINA DE CONCURSOS CEBRASPE - ${title}\n\n${concursos.join('\n\n')}`;
    }
    
    // Se n√£o encontrou concursos espec√≠ficos, retornar texto geral
    return '';
  }
  
  /**
   * Verifica se uma linha de texto parece ser nome de concurso
   */
  private isLikelyContestName(text: string): boolean {
    const contestKeywords = [
      'pol√≠cia', 'federal', 'civil', 'militar', 'bombeiros',
      'tribunal', 'trt', 'tre', 'trf', 'tjdft', 'tjba', 'tjce',
      'inss', 'ibama', 'anvisa', 'anatel', 'antt',
      'procurador', 'delegado', 'escriv√£o', 'agente',
      'auditor', 't√©cnico', 'analista',
      'prefeitura', 'c√¢mara', 'assembleia',
      'banco', 'banrisul', 'caixa',
      'universidade', 'ifb', 'unb', 'fub'
    ];
    
    const textLower = text.toLowerCase();
    
    // Deve ter pelo menos uma palavra-chave de concurso
    const hasKeyword = contestKeywords.some(keyword => textLower.includes(keyword));
    
    // Deve ter tamanho razo√°vel
    const hasReasonableLength = text.length >= 8 && text.length <= 100;
    
    // N√£o deve ser apenas n√∫meros ou caracteres especiais
    const hasLetters = /[a-zA-Z]/.test(text);
    
    return hasKeyword && hasReasonableLength && hasLetters;
  }

  /**
   * Detecta automaticamente se √© uma URL do Cebraspe e aplica l√≥gica espec√≠fica
   */
  private isCebraspeUrl(url: string): boolean {
    return url.includes('cebraspe.org.br') || url.includes('cespe.unb.br');
  }

  /**
   * Processa dados espec√≠ficos do Cebraspe extraindo informa√ß√µes estruturadas
   */
  private processCebraspeContent(content: string, url: string): {
    concursos: Array<{
      name: string;
      url: string;
      vagas: string;
      salario: string;
      orgao: string;
      cargo: string;
      status: string;
    }>;
  } {
    console.log('üèõÔ∏è Processando conte√∫do espec√≠fico do Cebraspe');
    
    const concursos: Array<{
      name: string;
      url: string;
      vagas: string;
      salario: string;
      orgao: string;
      cargo: string;
      status: string;
    }> = [];

    // Regex para extrair concursos do formato Cebraspe
    const concursoRegex = /###\s*([^#]+?)\s*(?:\n.*?(\d+\s+vagas))?.*?(?:At√©\s+(R\$[\d.,]+))?.*?\[MAIS INFORMA√á√ïES\]\((https:\/\/[^)]+)\)/gs;
    
    let match;
    while ((match = concursoRegex.exec(content)) !== null) {
      const [, nome, vagas, salario, concursoUrl] = match;
      
      if (nome && concursoUrl) {
        concursos.push({
          name: nome.trim(),
          url: concursoUrl.trim(),
          vagas: vagas || '',
          salario: salario || '',
          orgao: this.extractOrgaoFromName(nome.trim()),
          cargo: this.extractCargoFromName(nome.trim()),
          status: url.includes('encerrado') ? 'Encerrado' : 'Dispon√≠vel'
        });
      }
    }

    console.log(`‚úÖ Extra√≠dos ${concursos.length} concursos do Cebraspe`);
    return { concursos };
  }

  /**
   * Extrai nome do √≥rg√£o a partir do nome do concurso
   */
  private extractOrgaoFromName(name: string): string {
    const orgaoMap: Record<string, string> = {
      'ABIN': 'Ag√™ncia Brasileira de Intelig√™ncia',
      'AGU': 'Advocacia-Geral da Uni√£o',
      'ANAC': 'Ag√™ncia Nacional de Avia√ß√£o Civil',
      'ANVISA': 'Ag√™ncia Nacional de Vigil√¢ncia Sanit√°ria',
      'CBM': 'Corpo de Bombeiros Militar',
      'DPF': 'Departamento de Pol√≠cia Federal',
      'PRF': 'Pol√≠cia Rodovi√°ria Federal',
      'TCU': 'Tribunal de Contas da Uni√£o',
      'INSS': 'Instituto Nacional do Seguro Social'
    };

    for (const [sigla, nomeCompleto] of Object.entries(orgaoMap)) {
      if (name.toUpperCase().includes(sigla)) {
        return nomeCompleto;
      }
    }

    return name.split(' ')[0]; // Primeiro termo como fallback
  }

  /**
   * Extrai cargo a partir do nome do concurso
   */
  private extractCargoFromName(name: string): string {
    const cargoMap: Record<string, string> = {
      'DEFENSOR': 'Defensor P√∫blico',
      'ADVOGADO': 'Advogado',
      'AUDITOR': 'Auditor',
      'ANALISTA': 'Analista',
      'T√âCNICO': 'T√©cnico',
      'AGENTE': 'Agente',
      'POLICIAL': 'Policial',
      'BOMBEIRO': 'Bombeiro'
    };

    const nameUpper = name.toUpperCase();
    for (const [termo, cargo] of Object.entries(cargoMap)) {
      if (nameUpper.includes(termo)) {
        return cargo;
      }
    }

    return 'Servidor P√∫blico'; // Fallback gen√©rico
  }



  /**
   * Envia dados para Pinecone com retry em caso de erro
   */
  private async sendToPineconeWithRetry(
    id: string,
    chunks: { content: string; chunkIndex: number }[],
    metadata: any,
    maxRetries: number = 3
  ): Promise<void> {
    let lastError: Error | null = null;
    
    for (let attempt = 1; attempt <= maxRetries; attempt++) {
      try {
        console.log(`üîÑ Processando ${chunks.length} chunks para Pinecone...`);
        
        // Enviar para Pinecone
        await pineconeService.upsertDocument(id, chunks, metadata);
        
        console.log(`üì§ Batch ${attempt} enviado para Pinecone`);
        console.log(`‚úÖ Documento ${id} indexado no Pinecone com ${chunks.length} chunks`);
        
        return; // Sucesso, sair da fun√ß√£o
        
      } catch (error: any) {
        lastError = error;
        console.error(`‚ùå Tentativa ${attempt}/${maxRetries} falhou para ${id}:`, error.message);
        
        if (attempt < maxRetries) {
          const delay = Math.pow(2, attempt) * 1000; // Backoff exponencial
          console.log(`‚è≥ Aguardando ${delay}ms antes da pr√≥xima tentativa...`);
          await new Promise(resolve => setTimeout(resolve, delay));
        }
      }
    }
    
    // Se chegou aqui, todas as tentativas falharam
    throw new Error(`Falha ao enviar para Pinecone ap√≥s ${maxRetries} tentativas: ${lastError?.message}`);
  }

  /**
   * Quebra conte√∫do em chunks para processamento
   */
  private chunkContent(content: string, chunkSize: number = 1000): { content: string; chunkIndex: number }[] {
    const words = content.split(/\s+/);
    const chunks: { content: string; chunkIndex: number }[] = [];
    
    for (let i = 0; i < words.length; i += chunkSize) {
      const chunk = words.slice(i, i + chunkSize).join(' ');
      chunks.push({
        content: chunk,
        chunkIndex: chunks.length
      });
    }
    
    return chunks.length > 0 ? chunks : [{ content, chunkIndex: 0 }];
  }

  /**
   * Busca conte√∫do scrapado por tipo
   */
  async searchScrapedContent(
    query: string,
    searchTypes: string[],
    options: {
      topK?: number;
      minSimilarity?: number;
    } = {}
  ): Promise<any[]> {
    try {
      const { topK = 5, minSimilarity = 0.3 } = options;
      
      console.log(`üîç Buscando em conte√∫do scrapado: "${query}"`);
      console.log(`üìã Tipos de busca: ${searchTypes.join(', ')}`);
      
      // Buscar no Pinecone usando o namespace de admin
      const results = await pineconeService.searchSimilarContent(
        query,
        'admin_scraped',
        {
          topK,
          category: 'website',
          minSimilarity
        }
      );
      
      // Filtrar por tipos de busca e remover conte√∫do inv√°lido
      const filteredResults = results.filter((result: any) => {
        // Remover resultados com conte√∫do JavaScript inv√°lido ou marcadores de incompatibilidade
        if (result.content && (result.content.includes('SITE_REQUIRES_JAVASCRIPT') || (result.content.includes('javascript') && result.content.length < 100))) {
          console.log('‚ö†Ô∏è Removendo resultado de site incompat√≠vel (requer JavaScript)');
          return false;
        }
        
        // Tentar diferentes estruturas de metadata
        let searchTypesStr = result.metadata?.searchTypes || result.searchTypes || '';
        const resultTypes = searchTypesStr ? searchTypesStr.split(',') : [];
        return searchTypes.some(type => resultTypes.includes(type));
      });

      // Se n√£o h√° resultados v√°lidos, n√£o retornar nada
      if (filteredResults.length === 0 && results.length > 0) {
        console.log('‚ö†Ô∏è Nenhum resultado v√°lido encontrado nos sites configurados (conte√∫do requer JavaScript)');
        return [];
      }
      
      console.log(`üìä Encontrados ${filteredResults.length} resultados em conte√∫do scrapado`);
      
      return filteredResults.map((result: any) => ({
        id: `scraped_${Date.now()}_${Math.random()}`,
        name: result.title,
        url: result.metadata?.sourceUrl || '',
        description: result.content.substring(0, 200) + '...',
        fullContent: result.content,
        score: result.similarity,
        source: 'scraped'
      }));
      
    } catch (error) {
      console.error('‚ùå Erro na busca de conte√∫do scrapado:', error);
      return [];
    }
  }
  /**
   * Valida uma URL para ver se √© adequada para scraping
   */
  async validateUrlForScraping(url: string): Promise<{
    valid: boolean;
    accessible: boolean;
    scrapable: boolean;
    method?: 'simple' | 'advanced' | 'unsupported';
    error?: string;
    details?: string;
    suggestions?: string[];
  }> {
    try {
      console.log(`üîç Validando capacidade de scraping para: ${url}`);

      // Teste 1: Acessibilidade b√°sica
      let response;
      try {
        response = await fetch(url, {
          method: 'HEAD',
          headers: {
            'User-Agent': 'Mozilla/5.0 (compatible; NuP-est Bot; Educational Content Indexing)'
          },
          timeout: 10000
        });
      } catch (error) {
        return {
          valid: false,
          accessible: false,
          scrapable: false,
          error: "URL inacess√≠vel",
          details: "N√£o foi poss√≠vel conectar √† URL. Verifique se est√° correta e acess√≠vel."
        };
      }

      if (!response.ok) {
        return {
          valid: false,
          accessible: false,
          scrapable: false,
          error: `Erro HTTP ${response.status}`,
          details: "O servidor retornou um erro. Verifique se a URL est√° correta."
        };
      }

      console.log(`‚úÖ URL acess√≠vel (HTTP ${response.status})`);

      // Teste 2: Tentativa de scraping simples
      try {
        const scrapingTest = await this.testSimpleScraping(url);
        
        if (scrapingTest.success) {
          return {
            valid: true,
            accessible: true,
            scrapable: true,
            method: 'simple',
            details: `Scraping simples funcionou! Encontrado ${scrapingTest.contentLength} caracteres de conte√∫do √∫til.`,
            suggestions: [
              "Esta URL √© compat√≠vel com scraping simples",
              "O processamento ser√° r√°pido e eficiente",
              "Conte√∫do ser√° indexado automaticamente"
            ]
          };
        }
      } catch (error) {
        console.log(`‚ö†Ô∏è Scraping simples falhou: ${error}`);
      }

      // Teste 3: Verificar se pode usar m√©todos avan√ßados
      const contentType = response.headers.get('content-type') || '';
      
      if (contentType.includes('application/javascript') || 
          contentType.includes('application/json')) {
        return {
          valid: true,
          accessible: true,
          scrapable: false,
          method: 'unsupported',
          error: "Site requer JavaScript",
          details: "Este site usa conte√∫do gerado dinamicamente por JavaScript. Atualmente n√£o √© suportado.",
          suggestions: [
            "Procure uma vers√£o alternativa da p√°gina",
            "Verifique se existe uma API p√∫blica dispon√≠vel",
            "Entre em contato se este site for essencial"
          ]
        };
      }

      // Site acess√≠vel mas scraping simples falhou
      return {
        valid: true,
        accessible: true,
        scrapable: false,
        method: 'advanced',
        error: "Requer m√©todo avan√ßado",
        details: "Site acess√≠vel mas requer processamento mais avan√ßado. Funcionalidade em desenvolvimento.",
        suggestions: [
          "O site pode usar prote√ß√µes contra scraping",
          "Conte√∫do pode ser carregado dinamicamente",
          "Tentaremos processar com m√©todos alternativos"
        ]
      };

    } catch (error) {
      console.error(`‚ùå Erro na valida√ß√£o de scraping:`, error);
      return {
        valid: false,
        accessible: false,
        scrapable: false,
        error: "Erro interno",
        details: "Erro inesperado durante a valida√ß√£o. Tente novamente."
      };
    }
  }

  /**
   * Testa scraping simples em uma URL
   */
  private async testSimpleScraping(url: string): Promise<{
    success: boolean;
    contentLength: number;
    hasUsefulContent: boolean;
  }> {
    try {
      const response = await fetch(url, {
        headers: {
          'User-Agent': 'Mozilla/5.0 (compatible; NuP-est Bot; Educational Content Indexing)'
        },
        timeout: 15000
      });

      if (!response.ok) {
        throw new Error(`HTTP ${response.status}`);
      }

      const html = await response.text();
      const $ = cheerio.load(html);

      // Remover scripts, styles e outros elementos desnecess√°rios
      $('script, style, nav, footer, header, .advertisement, .ad').remove();

      // Extrair texto √∫til
      const bodyText = $('body').text().trim();
      const usefulContent = bodyText
        .replace(/\s+/g, ' ')
        .replace(/\n+/g, '\n')
        .trim();

      const hasUsefulContent = usefulContent.length > 200 && 
        /[a-zA-Z√Ä-√ø]/.test(usefulContent);

      return {
        success: hasUsefulContent,
        contentLength: usefulContent.length,
        hasUsefulContent
      };
    } catch (error) {
      return {
        success: false,
        contentLength: 0,
        hasUsefulContent: false
      };
    }
  }

  /**
   * Processa um website de forma inteligente e progressiva
   */
  async processWebsiteIntelligently(
    url: string,
    searchTypes: string[],
    siteId: string
  ): Promise<{
    success: boolean;
    method: 'simple' | 'structured' | 'advanced' | 'failed';
    documentsProcessed: number;
    error?: string;
    details?: string;
  }> {
    try {
      console.log(`üß† Iniciando processamento inteligente de: ${url}`);

      // Detectar se √© um site com padr√£o conhecido
      const sitePattern = this.detectSitePattern(url);
      
      if (sitePattern) {
        console.log(`üéØ Padr√£o detectado: ${sitePattern.name}`);
        return await this.processWithPattern(url, searchTypes, siteId, sitePattern);
      }

      // Tentar scraping simples
      console.log(`üîÑ Tentando processamento simples...`);
      try {
        const simpleResult = await this.processWithSimpleScraping(url, searchTypes, siteId);
        if (simpleResult.success) {
          return simpleResult;
        }
      } catch (error) {
        console.log(`‚ö†Ô∏è Processamento simples falhou: ${error}`);
      }

      // Se chegou aqui, tentar m√©todo avan√ßado (futuro)
      return {
        success: false,
        method: 'failed',
        documentsProcessed: 0,
        error: "M√©todo de processamento n√£o suportado",
        details: "Este site requer processamento avan√ßado que ainda n√£o est√° implementado."
      };

    } catch (error) {
      console.error(`‚ùå Erro no processamento inteligente:`, error);
      return {
        success: false,
        method: 'failed',
        documentsProcessed: 0,
        error: "Erro interno",
        details: String(error)
      };
    }
  }

  /**
   * Detecta padr√µes conhecidos de sites
   */
  private detectSitePattern(url: string): {
    name: string;
    type: 'competition' | 'education' | 'news' | 'generic';
    patterns: {
      titleSelector?: string;
      contentSelector?: string;
      listSelector?: string;
      linkSelector?: string;
    };
  } | null {
    const urlLower = url.toLowerCase();

    // Padr√£o para sites de concurso similares ao Cebraspe
    if (urlLower.includes('cebraspe.org.br') || urlLower.includes('cespe.unb.br')) {
      return {
        name: 'Cebraspe/Cespe',
        type: 'competition',
        patterns: {
          titleSelector: 'h3, .titulo, .concurso-nome',
          contentSelector: '.conteudo, .informacoes, .detalhes',
          listSelector: '.lista-concursos, .concursos',
          linkSelector: 'a[href*="concurso"], a[href*="edital"]'
        }
      };
    }

    // Adicionar mais padr√µes conforme necess√°rio
    return null;
  }

  /**
   * Processa usando padr√£o espec√≠fico detectado
   */
  private async processWithPattern(
    url: string,
    searchTypes: string[],
    siteId: string,
    pattern: { name: string; type: string; patterns: any }
  ): Promise<{
    success: boolean;
    method: 'structured';
    documentsProcessed: number;
    details?: string;
  }> {
    console.log(`üèóÔ∏è Processando com padr√£o ${pattern.name}`);

    try {
      // Para padr√£o Cebraspe, usar l√≥gica existente mas generalizada
      if (pattern.name === 'Cebraspe/Cespe') {
        const result = await this.processCompetitionSite(url, searchTypes, siteId);
        return {
          success: true,
          method: 'structured',
          documentsProcessed: result.count,
          details: `Processado usando padr√£o de concursos. ${result.count} itens indexados.`
        };
      }

      // Processar outros padr√µes conforme implementado
      throw new Error(`Padr√£o ${pattern.name} n√£o implementado ainda`);

    } catch (error) {
      throw new Error(`Erro no processamento com padr√£o: ${error}`);
    }
  }

  /**
   * Processa usando scraping simples
   */
  private async processWithSimpleScraping(
    url: string,
    searchTypes: string[],
    siteId: string
  ): Promise<{
    success: boolean;
    method: 'simple';
    documentsProcessed: number;
    details?: string;
  }> {
    console.log(`üìÑ Processando com scraping simples`);

    const pages = await this.realScrapeWithPagination(url, 10, 2);
    
    if (pages.length === 0) {
      throw new Error('Nenhuma p√°gina coletada');
    }

    let processedCount = 0;
    for (const page of pages) {
      const chunks = this.chunkContent(page.content, 1000);
      
      for (const chunk of chunks) {
        if (chunk.trim().length > 100) {
          const embedding = await embeddingsService.generateEmbedding(chunk);
          
          await pineconeService.upsertDocument({
            id: `${siteId}-page-${processedCount}-${Date.now()}`,
            content: chunk,
            metadata: {
              url: page.url,
              title: page.title,
              source: 'web-scraping',
              searchTypes: searchTypes,
              siteId: siteId,
              scrapedAt: new Date().toISOString()
            },
            embedding
          });
          
          processedCount++;
        }
      }
    }

    return {
      success: true,
      method: 'simple',
      documentsProcessed: processedCount,
      details: `Processamento simples conclu√≠do. ${processedCount} chunks indexados de ${pages.length} p√°ginas.`
    };
  }

  /**
   * Processa site de concursos (generaliza√ß√£o da l√≥gica Cebraspe)
   */
  private async processCompetitionSite(
    url: string,
    searchTypes: string[],
    siteId: string
  ): Promise<{ count: number }> {
    console.log(`üèõÔ∏è Processando site de concursos`);

    try {
      const response = await fetch(url, {
        headers: {
          'User-Agent': 'Mozilla/5.0 (compatible; NuP-est Bot; Educational Content Indexing)'
        }
      });

      if (!response.ok) {
        throw new Error(`HTTP ${response.status}`);
      }

      const content = await response.text();
      
      // Processar conte√∫do estruturado
      const competitions = this.extractCompetitionsFromContent(content, url);
      
      if (competitions.length === 0) {
        throw new Error('Nenhum concurso encontrado no conte√∫do');
      }

      // Indexar cada concurso
      let count = 0;
      for (const competition of competitions) {
        const competitionText = this.formatCompetitionForIndexing(competition);
        const embedding = await embeddingsService.generateEmbedding(competitionText);
        
        await pineconeService.upsertDocument({
          id: `${siteId}-competition-${count}-${Date.now()}`,
          content: competitionText,
          metadata: {
            url: competition.url,
            title: competition.name,
            source: 'competition-site',
            searchTypes: searchTypes,
            siteId: siteId,
            orgao: competition.orgao,
            cargo: competition.cargo,
            status: competition.status,
            scrapedAt: new Date().toISOString()
          },
          embedding
        });
        
        count++;
      }

      console.log(`‚úÖ Indexados ${count} concursos`);
      return { count };

    } catch (error) {
      console.error(`‚ùå Erro no processamento de concursos:`, error);
      throw error;
    }
  }

  /**
   * Extrai concursos do conte√∫do (vers√£o gen√©rica)
   */
  private extractCompetitionsFromContent(content: string, url: string): Array<{
    name: string;
    url: string;
    vagas: string;
    salario: string;
    orgao: string;
    cargo: string;
    status: string;
  }> {
    const competitions: Array<{
      name: string;
      url: string;
      vagas: string;
      salario: string;
      orgao: string;
      cargo: string;
      status: string;
    }> = [];

    // Padr√£o Cebraspe (mantido por compatibilidade)
    const cebraspeRegex = /###\s*([^#]+?)\s*(?:\n.*?(\d+\s+vagas))?.*?(?:At√©\s+(R\$[\d.,]+))?.*?\[MAIS INFORMA√á√ïES\]\((https:\/\/[^)]+)\)/gs;
    
    let match;
    while ((match = cebraspeRegex.exec(content)) !== null) {
      const [, nome, vagas, salario, concursoUrl] = match;
      
      if (nome && concursoUrl) {
        competitions.push({
          name: nome.trim(),
          url: concursoUrl.trim(),
          vagas: vagas || '',
          salario: salario || '',
          orgao: this.extractOrgaoFromName(nome.trim()),
          cargo: this.extractCargoFromName(nome.trim()),
          status: url.includes('encerrado') ? 'Encerrado' : 'Dispon√≠vel'
        });
      }
    }

    // TODO: Adicionar outros padr√µes de sites de concurso
    
    return competitions;
  }

  /**
   * Formatar concurso para indexa√ß√£o
   */
  private formatCompetitionForIndexing(competition: any): string {
    return `${competition.name}\n\n√ìrg√£o: ${competition.orgao}\nCargo: ${competition.cargo}\nStatus: ${competition.status}\nVagas: ${competition.vagas}\nSal√°rio: ${competition.salario}\nMais informa√ß√µes: ${competition.url}`;
  }
}

export const webScraperService = new WebScraperService();